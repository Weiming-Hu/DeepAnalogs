# "`-''-/").___..--''"`-._
#  (`6_ 6  )   `-.  (     ).`-.__.`)   WE ARE ...
#  (_Y_.)'  ._   )  `._ `. ``-..-'    PENN STATE!
#    _ ..`--'_..-_/  /--'_.' ,'
#  (il),-''  (li),'  ((!.-'
#
# Author: Weiming Hu <weiming@psu.edu>
#
#         Geoinformatics and Earth Observation Laboratory (http://geolab.psu.edu)
#         Department of Geography and Institute for Computational and Data Sciences
#         The Pennsylvania State University
#
# Date of Creation: 2021/04/08
#
# An example of supported arguments.
# Required options are marked as __REQUIRED__.
# Otherwise, a default value is provided.
#


##########################
# Section: IO parameters #
##########################

io:
    # Output directory
    # Example: /home/output
    #
    out: ~/tmp/DeepAnalogs

    # Input forecast NetCDF file (UTC time assumed)
    # Example: /home/forecasts.nc
    #
    forecast: ~/tmp/GFS_1p00.nc

    # Input observation NetCDF file (UTC time assumed)
    # Example: /home/observations.nc
    #
    observation: ~/tmp/SURFRAD_PennState.nc

    # YYYY/mm/dd HH:MM:DD for the start time of anchors (UTC time assumed)
    # Example: 2015/02/01 00:00:00
    #
    anchor_start: 2015/02/01 00:00:00

    # YYYY/mm/dd HH:MM:DD for the end time of anchors (UTC time assumed)
    # Example: 2019/10/31 23:59:59
    #
    anchor_end: 2015/02/15 23:59:59

    # YYYY/mm/dd HH:MM:DD to split the anchor period into train/test (UTC time assumed)
    # The split time will be included in the test period.
    # Example: 2018/01/01 00:00:00
    #
    split: 2015/02/07 00:00:00

    # YYYY/mm/dd HH:MM:DD for the start time of search (UTC time assumed)
    # Example: 2015/02/01 00:00:00
    #
    search_start: 2015/02/01 00:00:00

    # YYYY/mm/dd HH:MM:DD for the end time of search (UTC time assumed)
    # Example: 2017/12/31 23:59:59
    #
    search_end: 2015/02/15 23:59:59

############################
# Section: Data parameters #
############################

data:
    # The number of analogs
    # Example: 21
    #
    analogs: 2

    # Names or indices of forecast variables to use
    # Example: [0, 2, 4] or ['temperature', 'wind speed', 'wind direction']
    #
    fcst_variables: !!null

    # Weights for observation variables when calculating the reverse analogs
    # The default is equal weighting for all observation variables.
    # Example: [0, 0, 1, 0, 0] or [0.2, 0.2, 0.6]
    #
    obs_weights: !!null

    # The observation variable index that should always be positive
    # If the variable value is non-positive, it won't be used during training.
    # Example: 2
    positive_index: !!null

    # If the entire dataset is too large, set this probability carry out random sampling.
    triplet_sample_prob: 1.0

    # The sample method for selecting triplets
    # Can be one of fitness or sequential
    #
    triplet_sample_method: fitness

    # The number of negative cases for each positive case if the fitness sampling method is used
    # Example: 21
    #
    fitness_num_negative: 2

    # The margin used while creating the triplet dataset
    dataset_margin: np.nan

    # The station indices to subset after reading observations
    # Example: [0, 3, 5]
    #
    obs_stations_index: !!null

    # The station indices to subset after reading forecasts
    # Example: [0, 3, 5]
    #
    fcst_stations_index: !!null

    # The number of CPU to use during data preprocessig
    preprocess_workers: 4

    # If the file does not exist, a file will be saved with ready-to-train data.
    # If the file already exists, preprocessed data will be read directly from the file, skipping data preprocessing.
    #
    intermediate_file: ''

    # The weight for Julian days when calculating reverse analogs
    julian_weight: 0.0

    # The Dataset class to use
    # Can be one of AnEnDatasetOneToMany, AnEnDatasetWithTimeWindow, or AnEnDatasetSpatial
    # If 'use_conv_lstm' is True, this has to be 'AnEnDatasetSpatial'.
    #
    dataset_class: AnEnDatasetWithTimeWindow

    # The index of the forecast station to match the observation station
    # Only used when the Dataset class is 'AnEnDatasetOneToMany'
    #
    matching_forecast_station: -1


#############################
# Section: Model parameters #
#############################

model:
    # Dropout rate (a probability) or a list or dropout rates
    # Example: 0.0 or [0.1, 0.2, 0.3]
    #
    dropout: 0.0

    # Number of embeddings in the final output
    # Example: 20
    #
    lstm_output: 20

    # Number of embeddings in hidden layers
    # Example: 20
    #
    lstm_hidden: 20

    # Number of layers
    # Example: 2
    #
    lstm_layers: 2

    # The radius for constructing a time series centered at each forecast lead time
    lstm_radius: 1

    # Whether to use ConvLSTM to train a spatial metric
    use_conv_lstm: True

    # The kernel size for ConvLSTM layers
    # Can also be a list of kernel sizes
    # If multiple layers exist and only one kernel size is provided,
    # all layers will have the same kernel size as specified.
    #
    conv_kernel: 3

    # The kernel size for MaxPool layers
    # Can also be a list of kernel sizes
    # If multiple layers exist and only one kernel size is provided,
    # all layers will have the same kernel size as specified.
    #
    pool_kernel: 2

    # The grid file for aligning forecast stations
    forecast_grid_file: ~/tmp/GFS_1p00.txt

    # Width of the spatial mask
    spatial_mask_width: 5

    # Height of the spatial mask
    spatial_mask_height: 5

################################
# Section: Training parameters #
################################

train:
    # Learning rate
    lr: 0.001

    # Batch size during training
    train_batch: 32

    # Batch size during testing
    test_batch: 32

    # Training epochs
    epochs: 20

    # The scaling method to use while training the model
    # Can be one of MinMaxScaler or StandardScaler
    #
    scaler_type: MinMaxScaler

    # The number of parallel DataLoader workers during training
    train_loaders: 4

    # The number of parallel DataLoader workers during testing
    test_loaders: 4

    # Whether to use CPU for model training
    use_cpu: True

    # Triplet loss margin during training
    train_margin: 0.9

    # The optimizer to use
    # Can be one of Adam, AdamW, or RMSprop
    #
    optimizer: Adam

    # Whether to use amsgrad during training when Adam and the variates are used
    use_amsgrad: False

    # Weigth decay
    wdecay: 0.001
